{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.60'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "import os\n",
    "from radam import *\n",
    "from csvlogger import *\n",
    "from mish import *\n",
    "import cv2\n",
    "from albumentations import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 128\n",
    "bs = 64\n",
    "nfolds = 4\n",
    "fold = 0\n",
    "SEED = 43\n",
    "N = 12\n",
    "TRAIN = 'data/train_16x128x128'\n",
    "LABELS = 'data/train_d1.csv'\n",
    "OUT = 'd1'\n",
    "NUM_WORKERS = 12\n",
    "\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "      <th>isup_grade0</th>\n",
       "      <th>split</th>\n",
       "      <th>score</th>\n",
       "      <th>provider</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score  \\\n",
       "0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0   \n",
       "1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0   \n",
       "2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4   \n",
       "3  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4   \n",
       "4  001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0   \n",
       "\n",
       "   isup_grade0  split  score  provider  \n",
       "0            0      0      0      True  \n",
       "1            0      1      0      True  \n",
       "2            4      2      1     False  \n",
       "3            4      3      1      True  \n",
       "4            0      3      0      True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(LABELS).set_index('image_id')\n",
    "files = sorted(set([p[:32] for p in os.listdir(TRAIN)]))\n",
    "df.gleason_score = df.gleason_score.replace('negative','0+0')\n",
    "df = df.loc[files]\n",
    "df = df.reset_index()\n",
    "splits = StratifiedKFold(n_splits=nfolds, random_state=SEED, shuffle=True)\n",
    "splits = list(splits.split(df,df.isup_grade))\n",
    "folds_splits = np.zeros(len(df)).astype(np.int)\n",
    "for i in range(nfolds):\n",
    "    folds_splits[splits[i][1]] = i\n",
    "df['split'] = folds_splits\n",
    "Ng, Ns = df.nunique()[2], df.nunique()[3]\n",
    "score_map = {s:i for i,s in enumerate(df.gleason_score.unique())}\n",
    "df['score'] = df.gleason_score.map(score_map)\n",
    "df['provider'] = df.data_provider == 'karolinska'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([1.0-0.90949707, 1.0-0.8188697, 1.0-0.87795304])\n",
    "std = np.array([0.36357649, 0.49984502, 0.40477625])\n",
    "\n",
    "def img2tensor(img,dtype:np.dtype=np.float32):\n",
    "    if img.ndim==2 : img = np.expand_dims(img,2)\n",
    "    img = np.transpose(img,(2,0,1))\n",
    "    return torch.from_numpy(img.astype(dtype, copy=False))\n",
    "\n",
    "class PANDADataset(Dataset):\n",
    "    def __init__(self, df, fold=fold, train=True, tfms=None):\n",
    "        self.df = df.loc[df.split != fold].copy() if train else df.loc[df.split == fold].copy()\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        self.train = train\n",
    "        self.tfms = tfms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        labels = self.df.iloc[idx][['isup_grade','score','provider','isup_grade0']].astype(np.long).values\n",
    "        provider = self.df.iloc[idx].data_provider\n",
    "        \n",
    "        idx = self.df.iloc[idx].image_id\n",
    "        imgs = []\n",
    "        for i in range(N):\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(TRAIN,idx+'_'+str(i)+'.png')), cv2.COLOR_BGR2RGB)\n",
    "            img = 255 - img\n",
    "            if self.tfms is not None:\n",
    "                augmented = self.tfms(image=img)\n",
    "                img = augmented['image']\n",
    "            imgs.append(img)\n",
    "        imgs = [img2tensor((img/255.0 - mean)/std,np.float32) for img in imgs]\n",
    "\n",
    "        return torch.stack(imgs,0), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aug(p=1.0):\n",
    "    return Compose([\n",
    "        HorizontalFlip(),\n",
    "        VerticalFlip(),\n",
    "        RandomRotate90(),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.3, rotate_limit=15, p=0.9, \n",
    "                         border_mode=cv2.BORDER_CONSTANT),\n",
    "        #OneOf([\n",
    "        #    MotionBlur(blur_limit=3, p=0.1),\n",
    "        #    MedianBlur(blur_limit=3, p=0.1),\n",
    "        #    Blur(blur_limit=3, p=0.1),\n",
    "        #], p=0.2),\n",
    "        #OneOf([\n",
    "        #    OpticalDistortion(p=0.3),\n",
    "        #    GridDistortion(p=.1),\n",
    "        #    IAAPiecewiseAffine(p=0.3),\n",
    "        #], p=0.3),\n",
    "        OneOf([\n",
    "            HueSaturationValue(10,15,10),\n",
    "            CLAHE(clip_limit=2),\n",
    "            IAASharpen(),\n",
    "            RandomBrightnessContrast(),            \n",
    "        ], p=0.3),\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, arch='resnext50_32x4d_ssl', n=Ns, pre=True,ps=0.5):\n",
    "        super().__init__()\n",
    "        m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', arch)\n",
    "        nc = list(m.children())[-1].in_features\n",
    "        self.enc = nn.Sequential(*list(m.children())[:-2])\n",
    "        self.head = nn.Sequential(AdaptiveConcatPool2d(),Flatten(),\n",
    "                                  nn.Linear(2*nc,512),Mish(),nn.GroupNorm(32,512),\n",
    "                                  nn.Dropout(ps),nn.Linear(512,n+1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shape = x.shape\n",
    "        n = shape[1]\n",
    "        x = x.view(-1,shape[2],shape[3],shape[4])\n",
    "        x = self.enc(x)\n",
    "        \n",
    "        shape = x.shape\n",
    "        x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous()\\\n",
    "          .view(-1,shape[1],shape[2]*n,shape[3])\n",
    "        x = self.head(x)\n",
    "        return x[:,:1],x[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_shift = df.isup_grade.mean()\n",
    "def Kloss(x, target):\n",
    "    x = Ng*torch.sigmoid(x.float()).view(-1) - 0.5\n",
    "    target = target.float()\n",
    "    return 1.0 - (2.0*((x-y_shift)*(target-y_shift)).sum() - 1e-3)/\\\n",
    "        (((x-y_shift)**2).sum() + ((target-y_shift)**2).sum() + 1e-3)\n",
    "\n",
    "def Combine_loss(x, target):\n",
    "    loss_c = Kloss(x[0].float(),target[:,0])\n",
    "    loss_caux = F.cross_entropy(x[1].float(),target[:,1])\n",
    "    return loss_c + 0.1*loss_caux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DConfusionMatrix(Callback):\n",
    "    def __init__(self, provider=None, original=False, **kwargs):\n",
    "        self.provider=provider\n",
    "        self.original=original\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def on_train_begin(self, **kwargs):\n",
    "        self.n_classes = 0\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.cm = None\n",
    "\n",
    "    def on_batch_end(self, last_output:Tensor, last_target:Tensor, **kwargs):\n",
    "        if self.provider is None:\n",
    "            last_output = last_output[0]\n",
    "            last_target = last_target[:,0] if not self.original else last_target[:,3]\n",
    "        else:\n",
    "            idxs = last_target[:,2] == self.provider\n",
    "            last_output = last_output[0][idxs]\n",
    "            last_target = last_target[:,0][idxs]  if not self.original else last_target[:,3][idxs]\n",
    "            if len(last_output)  == 0: return\n",
    "        preds = torch.clamp((Ng*torch.sigmoid(last_output.float())).long().view(-1).cpu(),0,Ng-1)\n",
    "        targs = last_target.cpu()\n",
    "        if self.n_classes == 0:\n",
    "            self.n_classes = Ng\n",
    "            self.x = torch.arange(0, self.n_classes)\n",
    "        cm = ((preds==self.x[:, None]) & (targs==self.x[:, None, None])).sum(dim=2, dtype=torch.float32)\n",
    "        if self.cm is None: self.cm =  cm\n",
    "        else:               self.cm += cm\n",
    "\n",
    "    def on_epoch_end(self, **kwargs):\n",
    "        self.metric = self.cm\n",
    "\n",
    "class DKappaScore(DConfusionMatrix):\n",
    "    def __init__(self, weights:Optional[str]=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weights = weights\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        sum0 = self.cm.sum(dim=0)\n",
    "        sum1 = self.cm.sum(dim=1)\n",
    "        expected = torch.einsum('i,j->ij', (sum0, sum1)) / sum0.sum()\n",
    "        if self.weights is None:\n",
    "            w = torch.ones((self.n_classes, self.n_classes))\n",
    "            w[self.x, self.x] = 0\n",
    "        elif self.weights == \"linear\" or self.weights == \"quadratic\":\n",
    "            w = torch.zeros((self.n_classes, self.n_classes))\n",
    "            w += torch.arange(self.n_classes, dtype=torch.float)\n",
    "            w = torch.abs(w - torch.t(w)) if self.weights == \"linear\" else (w - torch.t(w)) ** 2\n",
    "        else: raise ValueError('Unknown weights. Expected None, \"linear\", or \"quadratic\".')\n",
    "        k = torch.sum(w * self.cm) / torch.sum(w * expected)\n",
    "        return add_metrics(last_metrics, 1-k)\n",
    "    \n",
    "class kappa_k(DKappaScore):\n",
    "    def __init__(self):\n",
    "        super().__init__(weights='quadratic',provider=1)\n",
    "        \n",
    "class kappa_r(DKappaScore):\n",
    "    def __init__(self):\n",
    "        super().__init__(weights='quadratic',provider=0)\n",
    "        \n",
    "class kappa_k0(DKappaScore):\n",
    "    def __init__(self):\n",
    "        super().__init__(weights='quadratic',provider=1,original=True)\n",
    "        \n",
    "class kappa_r0(DKappaScore):\n",
    "    def __init__(self):\n",
    "        super().__init__(weights='quadratic',provider=0,original=True)\n",
    "        \n",
    "class kappa0(DKappaScore):\n",
    "    def __init__(self):\n",
    "        super().__init__(weights='quadratic',original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/iafoss/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>d_kappa_score</th>\n",
       "      <th>kappa_k</th>\n",
       "      <th>kappa_r</th>\n",
       "      <th>kappa0</th>\n",
       "      <th>kappa_k0</th>\n",
       "      <th>kappa_r0</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.559850</td>\n",
       "      <td>0.400580</td>\n",
       "      <td>0.736352</td>\n",
       "      <td>0.662918</td>\n",
       "      <td>0.719059</td>\n",
       "      <td>0.702008</td>\n",
       "      <td>0.652163</td>\n",
       "      <td>0.661217</td>\n",
       "      <td>01:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.420296</td>\n",
       "      <td>0.369072</td>\n",
       "      <td>0.758162</td>\n",
       "      <td>0.729460</td>\n",
       "      <td>0.701591</td>\n",
       "      <td>0.720732</td>\n",
       "      <td>0.716369</td>\n",
       "      <td>0.636698</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.375028</td>\n",
       "      <td>0.347288</td>\n",
       "      <td>0.774504</td>\n",
       "      <td>0.734936</td>\n",
       "      <td>0.717273</td>\n",
       "      <td>0.736542</td>\n",
       "      <td>0.724937</td>\n",
       "      <td>0.648204</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.355469</td>\n",
       "      <td>0.290738</td>\n",
       "      <td>0.818576</td>\n",
       "      <td>0.757803</td>\n",
       "      <td>0.806316</td>\n",
       "      <td>0.777482</td>\n",
       "      <td>0.748402</td>\n",
       "      <td>0.733482</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.342032</td>\n",
       "      <td>0.315884</td>\n",
       "      <td>0.798101</td>\n",
       "      <td>0.766426</td>\n",
       "      <td>0.751933</td>\n",
       "      <td>0.756777</td>\n",
       "      <td>0.755097</td>\n",
       "      <td>0.678747</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.323345</td>\n",
       "      <td>0.277177</td>\n",
       "      <td>0.827450</td>\n",
       "      <td>0.790659</td>\n",
       "      <td>0.804889</td>\n",
       "      <td>0.787814</td>\n",
       "      <td>0.778517</td>\n",
       "      <td>0.736454</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.310577</td>\n",
       "      <td>0.475460</td>\n",
       "      <td>0.651920</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.727526</td>\n",
       "      <td>0.619953</td>\n",
       "      <td>0.503845</td>\n",
       "      <td>0.667388</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.304128</td>\n",
       "      <td>0.264425</td>\n",
       "      <td>0.840268</td>\n",
       "      <td>0.802979</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.798671</td>\n",
       "      <td>0.792552</td>\n",
       "      <td>0.747311</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.275856</td>\n",
       "      <td>0.288222</td>\n",
       "      <td>0.819175</td>\n",
       "      <td>0.763730</td>\n",
       "      <td>0.813679</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.755415</td>\n",
       "      <td>0.744826</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.294842</td>\n",
       "      <td>0.382508</td>\n",
       "      <td>0.735796</td>\n",
       "      <td>0.685274</td>\n",
       "      <td>0.707000</td>\n",
       "      <td>0.700422</td>\n",
       "      <td>0.674888</td>\n",
       "      <td>0.645386</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.275436</td>\n",
       "      <td>0.375634</td>\n",
       "      <td>0.751083</td>\n",
       "      <td>0.719005</td>\n",
       "      <td>0.713287</td>\n",
       "      <td>0.718318</td>\n",
       "      <td>0.709085</td>\n",
       "      <td>0.656996</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.269042</td>\n",
       "      <td>0.297875</td>\n",
       "      <td>0.809083</td>\n",
       "      <td>0.759090</td>\n",
       "      <td>0.799824</td>\n",
       "      <td>0.769925</td>\n",
       "      <td>0.748365</td>\n",
       "      <td>0.731541</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.269850</td>\n",
       "      <td>0.366424</td>\n",
       "      <td>0.769647</td>\n",
       "      <td>0.745390</td>\n",
       "      <td>0.741350</td>\n",
       "      <td>0.736797</td>\n",
       "      <td>0.739165</td>\n",
       "      <td>0.683327</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.258685</td>\n",
       "      <td>0.239430</td>\n",
       "      <td>0.858363</td>\n",
       "      <td>0.823616</td>\n",
       "      <td>0.845083</td>\n",
       "      <td>0.819871</td>\n",
       "      <td>0.813679</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.253802</td>\n",
       "      <td>0.267365</td>\n",
       "      <td>0.840335</td>\n",
       "      <td>0.797309</td>\n",
       "      <td>0.837568</td>\n",
       "      <td>0.802337</td>\n",
       "      <td>0.786342</td>\n",
       "      <td>0.773106</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.265179</td>\n",
       "      <td>0.840546</td>\n",
       "      <td>0.810618</td>\n",
       "      <td>0.823613</td>\n",
       "      <td>0.804818</td>\n",
       "      <td>0.800065</td>\n",
       "      <td>0.762225</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.237002</td>\n",
       "      <td>0.257784</td>\n",
       "      <td>0.850069</td>\n",
       "      <td>0.810861</td>\n",
       "      <td>0.836058</td>\n",
       "      <td>0.811829</td>\n",
       "      <td>0.800356</td>\n",
       "      <td>0.769341</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.224302</td>\n",
       "      <td>0.245896</td>\n",
       "      <td>0.850167</td>\n",
       "      <td>0.808719</td>\n",
       "      <td>0.842616</td>\n",
       "      <td>0.813183</td>\n",
       "      <td>0.800399</td>\n",
       "      <td>0.775846</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.219099</td>\n",
       "      <td>0.293609</td>\n",
       "      <td>0.810171</td>\n",
       "      <td>0.741637</td>\n",
       "      <td>0.808107</td>\n",
       "      <td>0.772316</td>\n",
       "      <td>0.730177</td>\n",
       "      <td>0.745989</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.213720</td>\n",
       "      <td>0.242701</td>\n",
       "      <td>0.859198</td>\n",
       "      <td>0.831251</td>\n",
       "      <td>0.840551</td>\n",
       "      <td>0.823876</td>\n",
       "      <td>0.822019</td>\n",
       "      <td>0.778140</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.212079</td>\n",
       "      <td>0.236005</td>\n",
       "      <td>0.861220</td>\n",
       "      <td>0.827913</td>\n",
       "      <td>0.853876</td>\n",
       "      <td>0.822477</td>\n",
       "      <td>0.817274</td>\n",
       "      <td>0.788418</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.194377</td>\n",
       "      <td>0.219270</td>\n",
       "      <td>0.872986</td>\n",
       "      <td>0.833955</td>\n",
       "      <td>0.867970</td>\n",
       "      <td>0.838569</td>\n",
       "      <td>0.825143</td>\n",
       "      <td>0.807091</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.192867</td>\n",
       "      <td>0.224575</td>\n",
       "      <td>0.869873</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.862480</td>\n",
       "      <td>0.836263</td>\n",
       "      <td>0.822253</td>\n",
       "      <td>0.804323</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.182873</td>\n",
       "      <td>0.222657</td>\n",
       "      <td>0.871550</td>\n",
       "      <td>0.824749</td>\n",
       "      <td>0.869854</td>\n",
       "      <td>0.839697</td>\n",
       "      <td>0.813404</td>\n",
       "      <td>0.816319</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.173055</td>\n",
       "      <td>0.214411</td>\n",
       "      <td>0.877448</td>\n",
       "      <td>0.841395</td>\n",
       "      <td>0.871306</td>\n",
       "      <td>0.845202</td>\n",
       "      <td>0.829478</td>\n",
       "      <td>0.817633</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.167051</td>\n",
       "      <td>0.219183</td>\n",
       "      <td>0.875279</td>\n",
       "      <td>0.843861</td>\n",
       "      <td>0.862660</td>\n",
       "      <td>0.844201</td>\n",
       "      <td>0.833103</td>\n",
       "      <td>0.809978</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.157592</td>\n",
       "      <td>0.220965</td>\n",
       "      <td>0.873402</td>\n",
       "      <td>0.825110</td>\n",
       "      <td>0.875802</td>\n",
       "      <td>0.840825</td>\n",
       "      <td>0.814464</td>\n",
       "      <td>0.820937</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.150707</td>\n",
       "      <td>0.208973</td>\n",
       "      <td>0.881430</td>\n",
       "      <td>0.841859</td>\n",
       "      <td>0.879748</td>\n",
       "      <td>0.847858</td>\n",
       "      <td>0.831563</td>\n",
       "      <td>0.822392</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.144389</td>\n",
       "      <td>0.210628</td>\n",
       "      <td>0.881155</td>\n",
       "      <td>0.839169</td>\n",
       "      <td>0.881888</td>\n",
       "      <td>0.847263</td>\n",
       "      <td>0.826799</td>\n",
       "      <td>0.825911</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.138402</td>\n",
       "      <td>0.210933</td>\n",
       "      <td>0.881694</td>\n",
       "      <td>0.836538</td>\n",
       "      <td>0.885164</td>\n",
       "      <td>0.848674</td>\n",
       "      <td>0.824946</td>\n",
       "      <td>0.829699</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.129294</td>\n",
       "      <td>0.212508</td>\n",
       "      <td>0.881083</td>\n",
       "      <td>0.837943</td>\n",
       "      <td>0.880457</td>\n",
       "      <td>0.851189</td>\n",
       "      <td>0.828176</td>\n",
       "      <td>0.829739</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.129598</td>\n",
       "      <td>0.212575</td>\n",
       "      <td>0.878184</td>\n",
       "      <td>0.833601</td>\n",
       "      <td>0.876655</td>\n",
       "      <td>0.847265</td>\n",
       "      <td>0.824150</td>\n",
       "      <td>0.823603</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.127247</td>\n",
       "      <td>0.211537</td>\n",
       "      <td>0.879667</td>\n",
       "      <td>0.836757</td>\n",
       "      <td>0.878716</td>\n",
       "      <td>0.849107</td>\n",
       "      <td>0.826689</td>\n",
       "      <td>0.826530</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.125833</td>\n",
       "      <td>0.211450</td>\n",
       "      <td>0.880448</td>\n",
       "      <td>0.835002</td>\n",
       "      <td>0.882544</td>\n",
       "      <td>0.849102</td>\n",
       "      <td>0.824453</td>\n",
       "      <td>0.829646</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.121394</td>\n",
       "      <td>0.211275</td>\n",
       "      <td>0.880290</td>\n",
       "      <td>0.835356</td>\n",
       "      <td>0.882229</td>\n",
       "      <td>0.849450</td>\n",
       "      <td>0.825749</td>\n",
       "      <td>0.829926</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.122474</td>\n",
       "      <td>0.215455</td>\n",
       "      <td>0.878704</td>\n",
       "      <td>0.836474</td>\n",
       "      <td>0.878623</td>\n",
       "      <td>0.848236</td>\n",
       "      <td>0.826736</td>\n",
       "      <td>0.826581</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with d_kappa_score value: 0.7363522052764893.\n",
      "Better model found at epoch 1 with d_kappa_score value: 0.7581620216369629.\n",
      "Better model found at epoch 2 with d_kappa_score value: 0.7745035886764526.\n",
      "Better model found at epoch 3 with d_kappa_score value: 0.8185763955116272.\n",
      "Better model found at epoch 5 with d_kappa_score value: 0.8274499177932739.\n",
      "Better model found at epoch 7 with d_kappa_score value: 0.8402683734893799.\n",
      "Better model found at epoch 13 with d_kappa_score value: 0.8583625555038452.\n",
      "Better model found at epoch 19 with d_kappa_score value: 0.8591977953910828.\n",
      "Better model found at epoch 20 with d_kappa_score value: 0.8612195253372192.\n",
      "Better model found at epoch 21 with d_kappa_score value: 0.8729861974716187.\n",
      "Better model found at epoch 24 with d_kappa_score value: 0.8774484992027283.\n",
      "Better model found at epoch 27 with d_kappa_score value: 0.8814295530319214.\n",
      "Better model found at epoch 29 with d_kappa_score value: 0.8816941976547241.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='42' class='' max='42', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [42/42 00:06<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/iafoss/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>d_kappa_score</th>\n",
       "      <th>kappa_k</th>\n",
       "      <th>kappa_r</th>\n",
       "      <th>kappa0</th>\n",
       "      <th>kappa_k0</th>\n",
       "      <th>kappa_r0</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.560236</td>\n",
       "      <td>0.451720</td>\n",
       "      <td>0.691130</td>\n",
       "      <td>0.669094</td>\n",
       "      <td>0.565739</td>\n",
       "      <td>0.663170</td>\n",
       "      <td>0.647881</td>\n",
       "      <td>0.528366</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.429245</td>\n",
       "      <td>0.367537</td>\n",
       "      <td>0.757546</td>\n",
       "      <td>0.657544</td>\n",
       "      <td>0.758863</td>\n",
       "      <td>0.719243</td>\n",
       "      <td>0.635635</td>\n",
       "      <td>0.700069</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.390836</td>\n",
       "      <td>0.297869</td>\n",
       "      <td>0.816388</td>\n",
       "      <td>0.736172</td>\n",
       "      <td>0.809850</td>\n",
       "      <td>0.778098</td>\n",
       "      <td>0.712356</td>\n",
       "      <td>0.749561</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.363210</td>\n",
       "      <td>0.290589</td>\n",
       "      <td>0.822925</td>\n",
       "      <td>0.738895</td>\n",
       "      <td>0.821118</td>\n",
       "      <td>0.785645</td>\n",
       "      <td>0.718385</td>\n",
       "      <td>0.760756</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.351997</td>\n",
       "      <td>0.315488</td>\n",
       "      <td>0.799963</td>\n",
       "      <td>0.738488</td>\n",
       "      <td>0.779036</td>\n",
       "      <td>0.762633</td>\n",
       "      <td>0.717505</td>\n",
       "      <td>0.719845</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.326820</td>\n",
       "      <td>0.268986</td>\n",
       "      <td>0.840036</td>\n",
       "      <td>0.769217</td>\n",
       "      <td>0.843303</td>\n",
       "      <td>0.799945</td>\n",
       "      <td>0.745276</td>\n",
       "      <td>0.780448</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.319133</td>\n",
       "      <td>0.363689</td>\n",
       "      <td>0.756077</td>\n",
       "      <td>0.685015</td>\n",
       "      <td>0.752184</td>\n",
       "      <td>0.726587</td>\n",
       "      <td>0.669164</td>\n",
       "      <td>0.704532</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.300136</td>\n",
       "      <td>0.290187</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.761738</td>\n",
       "      <td>0.818169</td>\n",
       "      <td>0.787404</td>\n",
       "      <td>0.738902</td>\n",
       "      <td>0.756541</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.298187</td>\n",
       "      <td>0.284694</td>\n",
       "      <td>0.823320</td>\n",
       "      <td>0.737524</td>\n",
       "      <td>0.823434</td>\n",
       "      <td>0.785505</td>\n",
       "      <td>0.716256</td>\n",
       "      <td>0.761976</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.290759</td>\n",
       "      <td>0.253101</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.796548</td>\n",
       "      <td>0.842509</td>\n",
       "      <td>0.812091</td>\n",
       "      <td>0.773634</td>\n",
       "      <td>0.784139</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.272556</td>\n",
       "      <td>0.336473</td>\n",
       "      <td>0.780794</td>\n",
       "      <td>0.680678</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.739106</td>\n",
       "      <td>0.653686</td>\n",
       "      <td>0.730520</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.267036</td>\n",
       "      <td>0.244637</td>\n",
       "      <td>0.855329</td>\n",
       "      <td>0.810415</td>\n",
       "      <td>0.843353</td>\n",
       "      <td>0.816104</td>\n",
       "      <td>0.786836</td>\n",
       "      <td>0.782491</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.269411</td>\n",
       "      <td>0.287607</td>\n",
       "      <td>0.822589</td>\n",
       "      <td>0.737426</td>\n",
       "      <td>0.831277</td>\n",
       "      <td>0.782636</td>\n",
       "      <td>0.713962</td>\n",
       "      <td>0.770253</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.263223</td>\n",
       "      <td>0.282777</td>\n",
       "      <td>0.826549</td>\n",
       "      <td>0.772010</td>\n",
       "      <td>0.826533</td>\n",
       "      <td>0.789783</td>\n",
       "      <td>0.751117</td>\n",
       "      <td>0.767887</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.250386</td>\n",
       "      <td>0.247079</td>\n",
       "      <td>0.853358</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>0.847876</td>\n",
       "      <td>0.813582</td>\n",
       "      <td>0.774269</td>\n",
       "      <td>0.785770</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.244988</td>\n",
       "      <td>0.293120</td>\n",
       "      <td>0.809813</td>\n",
       "      <td>0.720109</td>\n",
       "      <td>0.826944</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>0.698266</td>\n",
       "      <td>0.765982</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.237030</td>\n",
       "      <td>0.322113</td>\n",
       "      <td>0.792036</td>\n",
       "      <td>0.722901</td>\n",
       "      <td>0.801062</td>\n",
       "      <td>0.762567</td>\n",
       "      <td>0.705902</td>\n",
       "      <td>0.753726</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.234643</td>\n",
       "      <td>0.254320</td>\n",
       "      <td>0.848773</td>\n",
       "      <td>0.807527</td>\n",
       "      <td>0.836078</td>\n",
       "      <td>0.809101</td>\n",
       "      <td>0.782090</td>\n",
       "      <td>0.776588</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.221599</td>\n",
       "      <td>0.252573</td>\n",
       "      <td>0.851474</td>\n",
       "      <td>0.781046</td>\n",
       "      <td>0.855169</td>\n",
       "      <td>0.814674</td>\n",
       "      <td>0.756334</td>\n",
       "      <td>0.798458</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.220868</td>\n",
       "      <td>0.234287</td>\n",
       "      <td>0.864833</td>\n",
       "      <td>0.805072</td>\n",
       "      <td>0.869885</td>\n",
       "      <td>0.823366</td>\n",
       "      <td>0.779165</td>\n",
       "      <td>0.806934</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.206459</td>\n",
       "      <td>0.244377</td>\n",
       "      <td>0.856230</td>\n",
       "      <td>0.804740</td>\n",
       "      <td>0.857218</td>\n",
       "      <td>0.819547</td>\n",
       "      <td>0.780594</td>\n",
       "      <td>0.802089</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.196787</td>\n",
       "      <td>0.232436</td>\n",
       "      <td>0.863916</td>\n",
       "      <td>0.805648</td>\n",
       "      <td>0.872264</td>\n",
       "      <td>0.827604</td>\n",
       "      <td>0.780592</td>\n",
       "      <td>0.818019</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.188038</td>\n",
       "      <td>0.246783</td>\n",
       "      <td>0.851073</td>\n",
       "      <td>0.784367</td>\n",
       "      <td>0.865972</td>\n",
       "      <td>0.814832</td>\n",
       "      <td>0.760831</td>\n",
       "      <td>0.810285</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.184584</td>\n",
       "      <td>0.242082</td>\n",
       "      <td>0.856627</td>\n",
       "      <td>0.800521</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.822856</td>\n",
       "      <td>0.777376</td>\n",
       "      <td>0.806867</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.175389</td>\n",
       "      <td>0.239020</td>\n",
       "      <td>0.857536</td>\n",
       "      <td>0.787614</td>\n",
       "      <td>0.869572</td>\n",
       "      <td>0.821577</td>\n",
       "      <td>0.763467</td>\n",
       "      <td>0.815807</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.167279</td>\n",
       "      <td>0.229345</td>\n",
       "      <td>0.870125</td>\n",
       "      <td>0.807519</td>\n",
       "      <td>0.880590</td>\n",
       "      <td>0.832764</td>\n",
       "      <td>0.783248</td>\n",
       "      <td>0.823854</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.159465</td>\n",
       "      <td>0.228202</td>\n",
       "      <td>0.871057</td>\n",
       "      <td>0.814500</td>\n",
       "      <td>0.872137</td>\n",
       "      <td>0.834746</td>\n",
       "      <td>0.789240</td>\n",
       "      <td>0.817576</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.149948</td>\n",
       "      <td>0.218035</td>\n",
       "      <td>0.878338</td>\n",
       "      <td>0.825891</td>\n",
       "      <td>0.881167</td>\n",
       "      <td>0.842188</td>\n",
       "      <td>0.801515</td>\n",
       "      <td>0.826748</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.149467</td>\n",
       "      <td>0.218933</td>\n",
       "      <td>0.876608</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>0.882027</td>\n",
       "      <td>0.841285</td>\n",
       "      <td>0.794599</td>\n",
       "      <td>0.829304</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.145368</td>\n",
       "      <td>0.224534</td>\n",
       "      <td>0.873449</td>\n",
       "      <td>0.811568</td>\n",
       "      <td>0.886992</td>\n",
       "      <td>0.838639</td>\n",
       "      <td>0.787832</td>\n",
       "      <td>0.835290</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.134074</td>\n",
       "      <td>0.219191</td>\n",
       "      <td>0.876103</td>\n",
       "      <td>0.818263</td>\n",
       "      <td>0.886963</td>\n",
       "      <td>0.841084</td>\n",
       "      <td>0.794132</td>\n",
       "      <td>0.834852</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.129896</td>\n",
       "      <td>0.219613</td>\n",
       "      <td>0.878174</td>\n",
       "      <td>0.818794</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>0.843103</td>\n",
       "      <td>0.795866</td>\n",
       "      <td>0.837878</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.128077</td>\n",
       "      <td>0.221036</td>\n",
       "      <td>0.874347</td>\n",
       "      <td>0.811149</td>\n",
       "      <td>0.889280</td>\n",
       "      <td>0.839505</td>\n",
       "      <td>0.787935</td>\n",
       "      <td>0.836913</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.126566</td>\n",
       "      <td>0.226104</td>\n",
       "      <td>0.870827</td>\n",
       "      <td>0.810170</td>\n",
       "      <td>0.882936</td>\n",
       "      <td>0.837780</td>\n",
       "      <td>0.789018</td>\n",
       "      <td>0.832382</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.126458</td>\n",
       "      <td>0.219569</td>\n",
       "      <td>0.874308</td>\n",
       "      <td>0.814656</td>\n",
       "      <td>0.886350</td>\n",
       "      <td>0.838794</td>\n",
       "      <td>0.791336</td>\n",
       "      <td>0.832708</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.126195</td>\n",
       "      <td>0.217191</td>\n",
       "      <td>0.877098</td>\n",
       "      <td>0.814808</td>\n",
       "      <td>0.891113</td>\n",
       "      <td>0.841377</td>\n",
       "      <td>0.790646</td>\n",
       "      <td>0.837613</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with d_kappa_score value: 0.6911299228668213.\n",
      "Better model found at epoch 1 with d_kappa_score value: 0.7575457692146301.\n",
      "Better model found at epoch 2 with d_kappa_score value: 0.8163880109786987.\n",
      "Better model found at epoch 3 with d_kappa_score value: 0.8229246139526367.\n",
      "Better model found at epoch 5 with d_kappa_score value: 0.840036153793335.\n",
      "Better model found at epoch 9 with d_kappa_score value: 0.8498024940490723.\n",
      "Better model found at epoch 11 with d_kappa_score value: 0.8553290367126465.\n",
      "Better model found at epoch 19 with d_kappa_score value: 0.8648329973220825.\n",
      "Better model found at epoch 25 with d_kappa_score value: 0.870124876499176.\n",
      "Better model found at epoch 26 with d_kappa_score value: 0.8710570335388184.\n",
      "Better model found at epoch 27 with d_kappa_score value: 0.8783380389213562.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='42' class='' max='42', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [42/42 00:06<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/iafoss/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>d_kappa_score</th>\n",
       "      <th>kappa_k</th>\n",
       "      <th>kappa_r</th>\n",
       "      <th>kappa0</th>\n",
       "      <th>kappa_k0</th>\n",
       "      <th>kappa_r0</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.538944</td>\n",
       "      <td>0.397812</td>\n",
       "      <td>0.746545</td>\n",
       "      <td>0.700709</td>\n",
       "      <td>0.679233</td>\n",
       "      <td>0.711507</td>\n",
       "      <td>0.680392</td>\n",
       "      <td>0.625794</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.420902</td>\n",
       "      <td>0.330810</td>\n",
       "      <td>0.792605</td>\n",
       "      <td>0.700553</td>\n",
       "      <td>0.779348</td>\n",
       "      <td>0.751125</td>\n",
       "      <td>0.677489</td>\n",
       "      <td>0.714617</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.380144</td>\n",
       "      <td>0.387816</td>\n",
       "      <td>0.754783</td>\n",
       "      <td>0.659041</td>\n",
       "      <td>0.722067</td>\n",
       "      <td>0.714882</td>\n",
       "      <td>0.639098</td>\n",
       "      <td>0.657467</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.343255</td>\n",
       "      <td>0.287814</td>\n",
       "      <td>0.823210</td>\n",
       "      <td>0.783934</td>\n",
       "      <td>0.794167</td>\n",
       "      <td>0.779363</td>\n",
       "      <td>0.760843</td>\n",
       "      <td>0.725324</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.330577</td>\n",
       "      <td>0.312066</td>\n",
       "      <td>0.800285</td>\n",
       "      <td>0.739963</td>\n",
       "      <td>0.784935</td>\n",
       "      <td>0.758344</td>\n",
       "      <td>0.714923</td>\n",
       "      <td>0.723726</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.309815</td>\n",
       "      <td>0.282124</td>\n",
       "      <td>0.828561</td>\n",
       "      <td>0.793820</td>\n",
       "      <td>0.809109</td>\n",
       "      <td>0.786083</td>\n",
       "      <td>0.772485</td>\n",
       "      <td>0.742787</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.310466</td>\n",
       "      <td>0.283575</td>\n",
       "      <td>0.829554</td>\n",
       "      <td>0.786447</td>\n",
       "      <td>0.800590</td>\n",
       "      <td>0.785857</td>\n",
       "      <td>0.762465</td>\n",
       "      <td>0.731599</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.304779</td>\n",
       "      <td>0.267510</td>\n",
       "      <td>0.839959</td>\n",
       "      <td>0.775581</td>\n",
       "      <td>0.832105</td>\n",
       "      <td>0.795344</td>\n",
       "      <td>0.751729</td>\n",
       "      <td>0.762199</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.292920</td>\n",
       "      <td>0.278199</td>\n",
       "      <td>0.832289</td>\n",
       "      <td>0.814182</td>\n",
       "      <td>0.792996</td>\n",
       "      <td>0.789342</td>\n",
       "      <td>0.790252</td>\n",
       "      <td>0.726567</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.292102</td>\n",
       "      <td>0.301543</td>\n",
       "      <td>0.815179</td>\n",
       "      <td>0.800236</td>\n",
       "      <td>0.775451</td>\n",
       "      <td>0.773288</td>\n",
       "      <td>0.777712</td>\n",
       "      <td>0.711730</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.281624</td>\n",
       "      <td>0.313720</td>\n",
       "      <td>0.797878</td>\n",
       "      <td>0.740963</td>\n",
       "      <td>0.783330</td>\n",
       "      <td>0.757431</td>\n",
       "      <td>0.718083</td>\n",
       "      <td>0.722493</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.279146</td>\n",
       "      <td>0.245337</td>\n",
       "      <td>0.855673</td>\n",
       "      <td>0.822380</td>\n",
       "      <td>0.838478</td>\n",
       "      <td>0.808845</td>\n",
       "      <td>0.796981</td>\n",
       "      <td>0.765277</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.264566</td>\n",
       "      <td>0.409186</td>\n",
       "      <td>0.730411</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.731909</td>\n",
       "      <td>0.693529</td>\n",
       "      <td>0.651202</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.256800</td>\n",
       "      <td>0.253425</td>\n",
       "      <td>0.851068</td>\n",
       "      <td>0.820116</td>\n",
       "      <td>0.831282</td>\n",
       "      <td>0.808203</td>\n",
       "      <td>0.798808</td>\n",
       "      <td>0.763263</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.239584</td>\n",
       "      <td>0.312053</td>\n",
       "      <td>0.806617</td>\n",
       "      <td>0.780454</td>\n",
       "      <td>0.765781</td>\n",
       "      <td>0.768195</td>\n",
       "      <td>0.759729</td>\n",
       "      <td>0.704634</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.256645</td>\n",
       "      <td>0.272378</td>\n",
       "      <td>0.831015</td>\n",
       "      <td>0.797703</td>\n",
       "      <td>0.807530</td>\n",
       "      <td>0.785503</td>\n",
       "      <td>0.775192</td>\n",
       "      <td>0.734347</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.243598</td>\n",
       "      <td>0.263371</td>\n",
       "      <td>0.841341</td>\n",
       "      <td>0.763527</td>\n",
       "      <td>0.849982</td>\n",
       "      <td>0.799018</td>\n",
       "      <td>0.740303</td>\n",
       "      <td>0.782427</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.229373</td>\n",
       "      <td>0.235713</td>\n",
       "      <td>0.862727</td>\n",
       "      <td>0.818636</td>\n",
       "      <td>0.853002</td>\n",
       "      <td>0.818168</td>\n",
       "      <td>0.797569</td>\n",
       "      <td>0.781548</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.220983</td>\n",
       "      <td>0.297658</td>\n",
       "      <td>0.808253</td>\n",
       "      <td>0.724322</td>\n",
       "      <td>0.827891</td>\n",
       "      <td>0.765516</td>\n",
       "      <td>0.705041</td>\n",
       "      <td>0.761015</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.216391</td>\n",
       "      <td>0.238974</td>\n",
       "      <td>0.865989</td>\n",
       "      <td>0.831305</td>\n",
       "      <td>0.852831</td>\n",
       "      <td>0.826911</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.791497</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.209855</td>\n",
       "      <td>0.270606</td>\n",
       "      <td>0.834320</td>\n",
       "      <td>0.795844</td>\n",
       "      <td>0.822824</td>\n",
       "      <td>0.793652</td>\n",
       "      <td>0.777563</td>\n",
       "      <td>0.755370</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.194141</td>\n",
       "      <td>0.226653</td>\n",
       "      <td>0.870678</td>\n",
       "      <td>0.828180</td>\n",
       "      <td>0.862977</td>\n",
       "      <td>0.830892</td>\n",
       "      <td>0.805655</td>\n",
       "      <td>0.802105</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.192238</td>\n",
       "      <td>0.234733</td>\n",
       "      <td>0.863793</td>\n",
       "      <td>0.828546</td>\n",
       "      <td>0.851247</td>\n",
       "      <td>0.823204</td>\n",
       "      <td>0.805807</td>\n",
       "      <td>0.788866</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.179661</td>\n",
       "      <td>0.223527</td>\n",
       "      <td>0.873384</td>\n",
       "      <td>0.844207</td>\n",
       "      <td>0.857187</td>\n",
       "      <td>0.832787</td>\n",
       "      <td>0.821432</td>\n",
       "      <td>0.793790</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.169695</td>\n",
       "      <td>0.228749</td>\n",
       "      <td>0.870876</td>\n",
       "      <td>0.840330</td>\n",
       "      <td>0.859287</td>\n",
       "      <td>0.832540</td>\n",
       "      <td>0.822363</td>\n",
       "      <td>0.797300</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.170010</td>\n",
       "      <td>0.224260</td>\n",
       "      <td>0.872057</td>\n",
       "      <td>0.838501</td>\n",
       "      <td>0.857106</td>\n",
       "      <td>0.835949</td>\n",
       "      <td>0.820012</td>\n",
       "      <td>0.798742</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.159538</td>\n",
       "      <td>0.226595</td>\n",
       "      <td>0.872395</td>\n",
       "      <td>0.835391</td>\n",
       "      <td>0.867094</td>\n",
       "      <td>0.836032</td>\n",
       "      <td>0.817541</td>\n",
       "      <td>0.809457</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.149602</td>\n",
       "      <td>0.221106</td>\n",
       "      <td>0.875415</td>\n",
       "      <td>0.840148</td>\n",
       "      <td>0.869670</td>\n",
       "      <td>0.838558</td>\n",
       "      <td>0.822121</td>\n",
       "      <td>0.811004</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.138465</td>\n",
       "      <td>0.222709</td>\n",
       "      <td>0.873616</td>\n",
       "      <td>0.840164</td>\n",
       "      <td>0.863550</td>\n",
       "      <td>0.837685</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.806868</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.137310</td>\n",
       "      <td>0.219030</td>\n",
       "      <td>0.877134</td>\n",
       "      <td>0.837336</td>\n",
       "      <td>0.873073</td>\n",
       "      <td>0.840827</td>\n",
       "      <td>0.818886</td>\n",
       "      <td>0.816091</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.131472</td>\n",
       "      <td>0.218012</td>\n",
       "      <td>0.879812</td>\n",
       "      <td>0.844635</td>\n",
       "      <td>0.871790</td>\n",
       "      <td>0.843842</td>\n",
       "      <td>0.826171</td>\n",
       "      <td>0.814762</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.123273</td>\n",
       "      <td>0.217099</td>\n",
       "      <td>0.879114</td>\n",
       "      <td>0.842317</td>\n",
       "      <td>0.871773</td>\n",
       "      <td>0.842555</td>\n",
       "      <td>0.824189</td>\n",
       "      <td>0.813260</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.122324</td>\n",
       "      <td>0.216622</td>\n",
       "      <td>0.880572</td>\n",
       "      <td>0.849633</td>\n",
       "      <td>0.869388</td>\n",
       "      <td>0.845430</td>\n",
       "      <td>0.831613</td>\n",
       "      <td>0.813942</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.123564</td>\n",
       "      <td>0.214184</td>\n",
       "      <td>0.882878</td>\n",
       "      <td>0.848645</td>\n",
       "      <td>0.874158</td>\n",
       "      <td>0.847041</td>\n",
       "      <td>0.830648</td>\n",
       "      <td>0.816871</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.121328</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.884291</td>\n",
       "      <td>0.852457</td>\n",
       "      <td>0.875339</td>\n",
       "      <td>0.848625</td>\n",
       "      <td>0.834382</td>\n",
       "      <td>0.818546</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.118456</td>\n",
       "      <td>0.215225</td>\n",
       "      <td>0.882744</td>\n",
       "      <td>0.851883</td>\n",
       "      <td>0.872648</td>\n",
       "      <td>0.846836</td>\n",
       "      <td>0.834007</td>\n",
       "      <td>0.815202</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with d_kappa_score value: 0.7465454339981079.\n",
      "Better model found at epoch 1 with d_kappa_score value: 0.7926052808761597.\n",
      "Better model found at epoch 3 with d_kappa_score value: 0.8232097625732422.\n",
      "Better model found at epoch 5 with d_kappa_score value: 0.8285610675811768.\n",
      "Better model found at epoch 6 with d_kappa_score value: 0.82955402135849.\n",
      "Better model found at epoch 7 with d_kappa_score value: 0.8399591445922852.\n",
      "Better model found at epoch 11 with d_kappa_score value: 0.8556734323501587.\n",
      "Better model found at epoch 17 with d_kappa_score value: 0.8627267479896545.\n",
      "Better model found at epoch 19 with d_kappa_score value: 0.8659891486167908.\n",
      "Better model found at epoch 21 with d_kappa_score value: 0.8706778287887573.\n",
      "Better model found at epoch 23 with d_kappa_score value: 0.8733838200569153.\n",
      "Better model found at epoch 27 with d_kappa_score value: 0.8754150867462158.\n",
      "Better model found at epoch 29 with d_kappa_score value: 0.8771340847015381.\n",
      "Better model found at epoch 30 with d_kappa_score value: 0.8798118829727173.\n",
      "Better model found at epoch 32 with d_kappa_score value: 0.8805722594261169.\n",
      "Better model found at epoch 33 with d_kappa_score value: 0.8828780055046082.\n",
      "Better model found at epoch 34 with d_kappa_score value: 0.8842909932136536.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='42' class='' max='42', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [42/42 00:06<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/iafoss/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>d_kappa_score</th>\n",
       "      <th>kappa_k</th>\n",
       "      <th>kappa_r</th>\n",
       "      <th>kappa0</th>\n",
       "      <th>kappa_k0</th>\n",
       "      <th>kappa_r0</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.550755</td>\n",
       "      <td>0.399086</td>\n",
       "      <td>0.745308</td>\n",
       "      <td>0.657568</td>\n",
       "      <td>0.719653</td>\n",
       "      <td>0.704506</td>\n",
       "      <td>0.634487</td>\n",
       "      <td>0.658604</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.435932</td>\n",
       "      <td>0.376373</td>\n",
       "      <td>0.751285</td>\n",
       "      <td>0.563407</td>\n",
       "      <td>0.782431</td>\n",
       "      <td>0.709021</td>\n",
       "      <td>0.541167</td>\n",
       "      <td>0.716801</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.371888</td>\n",
       "      <td>0.303651</td>\n",
       "      <td>0.813159</td>\n",
       "      <td>0.740175</td>\n",
       "      <td>0.788832</td>\n",
       "      <td>0.769571</td>\n",
       "      <td>0.714273</td>\n",
       "      <td>0.721448</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.368971</td>\n",
       "      <td>0.332822</td>\n",
       "      <td>0.784060</td>\n",
       "      <td>0.752128</td>\n",
       "      <td>0.729091</td>\n",
       "      <td>0.743782</td>\n",
       "      <td>0.730341</td>\n",
       "      <td>0.667384</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.329287</td>\n",
       "      <td>0.276173</td>\n",
       "      <td>0.826485</td>\n",
       "      <td>0.754317</td>\n",
       "      <td>0.816677</td>\n",
       "      <td>0.778438</td>\n",
       "      <td>0.728983</td>\n",
       "      <td>0.742116</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.315704</td>\n",
       "      <td>0.281812</td>\n",
       "      <td>0.823728</td>\n",
       "      <td>0.732106</td>\n",
       "      <td>0.823688</td>\n",
       "      <td>0.775669</td>\n",
       "      <td>0.704473</td>\n",
       "      <td>0.749491</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.300318</td>\n",
       "      <td>0.274189</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.783102</td>\n",
       "      <td>0.822480</td>\n",
       "      <td>0.788038</td>\n",
       "      <td>0.757777</td>\n",
       "      <td>0.752913</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.305398</td>\n",
       "      <td>0.291682</td>\n",
       "      <td>0.818023</td>\n",
       "      <td>0.772518</td>\n",
       "      <td>0.782277</td>\n",
       "      <td>0.772987</td>\n",
       "      <td>0.748853</td>\n",
       "      <td>0.711240</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.286935</td>\n",
       "      <td>0.438386</td>\n",
       "      <td>0.695114</td>\n",
       "      <td>0.608522</td>\n",
       "      <td>0.664332</td>\n",
       "      <td>0.657070</td>\n",
       "      <td>0.585418</td>\n",
       "      <td>0.611304</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.279465</td>\n",
       "      <td>0.261604</td>\n",
       "      <td>0.842281</td>\n",
       "      <td>0.800506</td>\n",
       "      <td>0.826350</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.774609</td>\n",
       "      <td>0.752098</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.293475</td>\n",
       "      <td>0.820458</td>\n",
       "      <td>0.774997</td>\n",
       "      <td>0.796690</td>\n",
       "      <td>0.779025</td>\n",
       "      <td>0.756084</td>\n",
       "      <td>0.729618</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.264965</td>\n",
       "      <td>0.266699</td>\n",
       "      <td>0.836842</td>\n",
       "      <td>0.791749</td>\n",
       "      <td>0.822955</td>\n",
       "      <td>0.791710</td>\n",
       "      <td>0.765203</td>\n",
       "      <td>0.757200</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.258074</td>\n",
       "      <td>0.277579</td>\n",
       "      <td>0.827245</td>\n",
       "      <td>0.767556</td>\n",
       "      <td>0.821154</td>\n",
       "      <td>0.783802</td>\n",
       "      <td>0.741054</td>\n",
       "      <td>0.756936</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.256422</td>\n",
       "      <td>0.253613</td>\n",
       "      <td>0.847854</td>\n",
       "      <td>0.804574</td>\n",
       "      <td>0.827374</td>\n",
       "      <td>0.804399</td>\n",
       "      <td>0.779680</td>\n",
       "      <td>0.760496</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.257133</td>\n",
       "      <td>0.342095</td>\n",
       "      <td>0.776304</td>\n",
       "      <td>0.663424</td>\n",
       "      <td>0.786031</td>\n",
       "      <td>0.733950</td>\n",
       "      <td>0.638959</td>\n",
       "      <td>0.725944</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.247338</td>\n",
       "      <td>0.273209</td>\n",
       "      <td>0.833380</td>\n",
       "      <td>0.800062</td>\n",
       "      <td>0.807523</td>\n",
       "      <td>0.791094</td>\n",
       "      <td>0.778550</td>\n",
       "      <td>0.740867</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.238751</td>\n",
       "      <td>0.253043</td>\n",
       "      <td>0.844080</td>\n",
       "      <td>0.793192</td>\n",
       "      <td>0.835740</td>\n",
       "      <td>0.800948</td>\n",
       "      <td>0.770357</td>\n",
       "      <td>0.769411</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.220633</td>\n",
       "      <td>0.229325</td>\n",
       "      <td>0.864275</td>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.863688</td>\n",
       "      <td>0.819349</td>\n",
       "      <td>0.780476</td>\n",
       "      <td>0.793587</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.217298</td>\n",
       "      <td>0.271102</td>\n",
       "      <td>0.830554</td>\n",
       "      <td>0.745863</td>\n",
       "      <td>0.838413</td>\n",
       "      <td>0.786027</td>\n",
       "      <td>0.720132</td>\n",
       "      <td>0.773334</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.207343</td>\n",
       "      <td>0.251756</td>\n",
       "      <td>0.849058</td>\n",
       "      <td>0.799571</td>\n",
       "      <td>0.837873</td>\n",
       "      <td>0.808461</td>\n",
       "      <td>0.779847</td>\n",
       "      <td>0.772071</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.200706</td>\n",
       "      <td>0.229425</td>\n",
       "      <td>0.862841</td>\n",
       "      <td>0.804081</td>\n",
       "      <td>0.862297</td>\n",
       "      <td>0.820770</td>\n",
       "      <td>0.782435</td>\n",
       "      <td>0.796418</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.187850</td>\n",
       "      <td>0.247690</td>\n",
       "      <td>0.854987</td>\n",
       "      <td>0.811362</td>\n",
       "      <td>0.842948</td>\n",
       "      <td>0.814772</td>\n",
       "      <td>0.789968</td>\n",
       "      <td>0.779222</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.184088</td>\n",
       "      <td>0.239280</td>\n",
       "      <td>0.858766</td>\n",
       "      <td>0.800510</td>\n",
       "      <td>0.851178</td>\n",
       "      <td>0.818893</td>\n",
       "      <td>0.780114</td>\n",
       "      <td>0.787488</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.179352</td>\n",
       "      <td>0.225872</td>\n",
       "      <td>0.870879</td>\n",
       "      <td>0.817327</td>\n",
       "      <td>0.871815</td>\n",
       "      <td>0.828712</td>\n",
       "      <td>0.793328</td>\n",
       "      <td>0.808005</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.170187</td>\n",
       "      <td>0.218501</td>\n",
       "      <td>0.872092</td>\n",
       "      <td>0.817525</td>\n",
       "      <td>0.873509</td>\n",
       "      <td>0.831618</td>\n",
       "      <td>0.793452</td>\n",
       "      <td>0.812587</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.162106</td>\n",
       "      <td>0.223618</td>\n",
       "      <td>0.869025</td>\n",
       "      <td>0.803733</td>\n",
       "      <td>0.874504</td>\n",
       "      <td>0.828970</td>\n",
       "      <td>0.782764</td>\n",
       "      <td>0.812337</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.154465</td>\n",
       "      <td>0.221565</td>\n",
       "      <td>0.871471</td>\n",
       "      <td>0.823108</td>\n",
       "      <td>0.867708</td>\n",
       "      <td>0.830320</td>\n",
       "      <td>0.799534</td>\n",
       "      <td>0.805771</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.148012</td>\n",
       "      <td>0.223046</td>\n",
       "      <td>0.869315</td>\n",
       "      <td>0.815648</td>\n",
       "      <td>0.869233</td>\n",
       "      <td>0.827799</td>\n",
       "      <td>0.792519</td>\n",
       "      <td>0.806069</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.140074</td>\n",
       "      <td>0.227211</td>\n",
       "      <td>0.865247</td>\n",
       "      <td>0.799862</td>\n",
       "      <td>0.869390</td>\n",
       "      <td>0.826617</td>\n",
       "      <td>0.777223</td>\n",
       "      <td>0.810683</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.132608</td>\n",
       "      <td>0.220561</td>\n",
       "      <td>0.871784</td>\n",
       "      <td>0.808422</td>\n",
       "      <td>0.876695</td>\n",
       "      <td>0.832955</td>\n",
       "      <td>0.786485</td>\n",
       "      <td>0.817281</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.132736</td>\n",
       "      <td>0.221619</td>\n",
       "      <td>0.870072</td>\n",
       "      <td>0.810484</td>\n",
       "      <td>0.873638</td>\n",
       "      <td>0.832493</td>\n",
       "      <td>0.788694</td>\n",
       "      <td>0.816115</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.124980</td>\n",
       "      <td>0.219947</td>\n",
       "      <td>0.872954</td>\n",
       "      <td>0.813246</td>\n",
       "      <td>0.876978</td>\n",
       "      <td>0.834174</td>\n",
       "      <td>0.790086</td>\n",
       "      <td>0.818672</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.120010</td>\n",
       "      <td>0.220338</td>\n",
       "      <td>0.869942</td>\n",
       "      <td>0.803289</td>\n",
       "      <td>0.877755</td>\n",
       "      <td>0.831514</td>\n",
       "      <td>0.780268</td>\n",
       "      <td>0.819523</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.119308</td>\n",
       "      <td>0.218895</td>\n",
       "      <td>0.875177</td>\n",
       "      <td>0.816572</td>\n",
       "      <td>0.879038</td>\n",
       "      <td>0.836019</td>\n",
       "      <td>0.794290</td>\n",
       "      <td>0.819255</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.116834</td>\n",
       "      <td>0.219394</td>\n",
       "      <td>0.876482</td>\n",
       "      <td>0.820817</td>\n",
       "      <td>0.879222</td>\n",
       "      <td>0.837738</td>\n",
       "      <td>0.798993</td>\n",
       "      <td>0.819935</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.114507</td>\n",
       "      <td>0.218955</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.821308</td>\n",
       "      <td>0.880100</td>\n",
       "      <td>0.838375</td>\n",
       "      <td>0.799321</td>\n",
       "      <td>0.821305</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with d_kappa_score value: 0.7453080415725708.\n",
      "Better model found at epoch 1 with d_kappa_score value: 0.751285195350647.\n",
      "Better model found at epoch 2 with d_kappa_score value: 0.8131594657897949.\n",
      "Better model found at epoch 4 with d_kappa_score value: 0.826484739780426.\n",
      "Better model found at epoch 6 with d_kappa_score value: 0.8339618444442749.\n",
      "Better model found at epoch 9 with d_kappa_score value: 0.8422808647155762.\n",
      "Better model found at epoch 13 with d_kappa_score value: 0.8478544354438782.\n",
      "Better model found at epoch 17 with d_kappa_score value: 0.8642752766609192.\n",
      "Better model found at epoch 23 with d_kappa_score value: 0.8708791732788086.\n",
      "Better model found at epoch 24 with d_kappa_score value: 0.8720924854278564.\n",
      "Better model found at epoch 31 with d_kappa_score value: 0.8729544281959534.\n",
      "Better model found at epoch 33 with d_kappa_score value: 0.8751765489578247.\n",
      "Better model found at epoch 34 with d_kappa_score value: 0.8764822483062744.\n",
      "Better model found at epoch 35 with d_kappa_score value: 0.8769035935401917.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='42' class='' max='42', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [42/42 00:06<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8803126684578566\n",
      "[[2190  431   62   21    3    0]\n",
      " [ 434 1673  454   82   17    2]\n",
      " [  66  407  639  283   52    5]\n",
      " [  20   90  227  507  342   52]\n",
      " [  18   44   69  248  713  383]\n",
      " [   6    6   15   40  191  724]]\n"
     ]
    }
   ],
   "source": [
    "fname = 'RNXT50_s43'\n",
    "pred,pred_y = [],[]\n",
    "for fold in range(nfolds):\n",
    "    ds_t = PANDADataset(df, fold=fold, train=True, tfms=get_aug())\n",
    "    ds_v = PANDADataset(df, fold=fold, train=False)\n",
    "    data = DataBunch.create(ds_t,ds_v,bs=bs,num_workers=NUM_WORKERS)\n",
    "    model = nn.DataParallel(Model())\n",
    "    learn = Learner(data, model, loss_func=Combine_loss, opt_func=Over9000, \n",
    "                metrics=[DKappaScore(weights='quadratic'),kappa_k(),kappa_r(),\n",
    "                         kappa0(),kappa_k0(),kappa_r0()]).to_fp16()\n",
    "    logger = CSVLogger(learn,os.path.join(OUT,f'log_{fname}_{fold}'))\n",
    "    learn.clip_grad = 1.0\n",
    "    learn.split([model.module.head])\n",
    "    learn.unfreeze()\n",
    "\n",
    "    learn.fit_one_cycle(36, max_lr=slice(0.5e-3,0.2e-2), div_factor=50, pct_start=0.0, \n",
    "      callbacks = [SaveModelCallback(learn,name=f'model',monitor='d_kappa_score')])\n",
    "    torch.save(learn.model.module.state_dict(),os.path.join(OUT,f'{fname}_{fold}.pth'))\n",
    "    \n",
    "    learn.model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, (x, y) in progress_bar(enumerate(data.dl(DatasetType.Valid)),\n",
    "                                     total=len(data.dl(DatasetType.Valid))):\n",
    "            p = learn.model(x.cuda().half())\n",
    "            pred.append(p[0].float().view(-1).cpu())\n",
    "            pred_y.append(y[:,0].cpu())\n",
    "            \n",
    "p = torch.clamp((6.0*torch.sigmoid(torch.cat(pred))).long(),0,Ng-1)\n",
    "t = torch.cat(pred_y)\n",
    "print(cohen_kappa_score(p,t,weights='quadratic'))\n",
    "print(confusion_matrix(t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "20e38c4548404cc98607c76ae53550d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23b404b089e24eb79ed379288411b777": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3a4db8fe4bfd4fdc8012737932ea22ad",
       "placeholder": "",
       "style": "IPY_MODEL_ab9144ff62b64e3aa66c99ea2aee85f9",
       "value": " 95.8M/95.8M [00:01&lt;00:00, 82.4MB/s]"
      }
     },
     "28426ef9c59a4cdd87402bb9fd622f5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_20e38c4548404cc98607c76ae53550d0",
       "max": 100428550,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e3d4a0df7b1741ec84a6348c61f956b0",
       "value": 100428550
      }
     },
     "3a4db8fe4bfd4fdc8012737932ea22ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ab9144ff62b64e3aa66c99ea2aee85f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "adf5cac68ad047e2b76cf7e670f69a62": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3d4a0df7b1741ec84a6348c61f956b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f21d12ecfe034765bf22e796b68962a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_28426ef9c59a4cdd87402bb9fd622f5a",
        "IPY_MODEL_23b404b089e24eb79ed379288411b777"
       ],
       "layout": "IPY_MODEL_adf5cac68ad047e2b76cf7e670f69a62"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
